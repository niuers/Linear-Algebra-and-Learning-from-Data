{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\git\\Linear-Algebra-and-Learning-from-Data\n"
     ]
    }
   ],
   "source": [
    "# Add lib input sys.path\n",
    "import os\n",
    "import sys\n",
    "nb_dir = os.getcwd() #os.path.split(os.getcwd())\n",
    "print(nb_dir)\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lib.matrix as mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Set I.1\n",
    "#### Problem I.1.1\n",
    "\n",
    "The example\n",
    "\n",
    "\\begin{align*}\n",
    "1\\times \\begin{bmatrix}0\\\\1\\\\2\\\\ 3\\end{bmatrix} + 1 \\times \\begin{bmatrix}1\\\\2\\\\-1\\\\-3\\end{bmatrix} - 1 \\times \\begin{bmatrix}1\\\\3\\\\1\\\\0\\end{bmatrix} &= \\begin{bmatrix}0\\\\0\\\\0\\\\0\\end{bmatrix}\\\\\n",
    "\\end{align*}\n",
    "\n",
    "Let $A=\\begin{bmatrix}0&1 &1 \\\\1 &2 &3\\\\ 2 & -1 & 1\\\\3 & -3 & 0\\end{bmatrix}$ and $x = \\begin{bmatrix}1\\\\1\\\\-1\\end{bmatrix}$, we have $A_{4\\times 3}x_{3\\times 1}=0_{4\\times 1}$.\n",
    "\n",
    "#### Problem I.1.2 \n",
    "\n",
    "The two solutions for $Az=0$ are: $z = x-y$ and $z=y-x$.\n",
    "\n",
    "#### Problem I.1.3\n",
    "\n",
    "* (1) $Ac = 0$, where $A = \\begin{bmatrix}a_1 & a_2 & \\dots & a_n\\end{bmatrix}_{m \\times n}$, and $c = \\begin{bmatrix}c_1 \\\\ c_2\\\\ \\vdots \\\\ c_n\\end{bmatrix}_{n \\times 1}$\n",
    "\n",
    "* (2) $\\sum^n_{j=1} a_{ij}c_j = 0$ for $i = 1, 2, \\dots, m$\n",
    "\n",
    "#### Problem I.1.4\n",
    "\n",
    "We have two solutions $x = \\begin{bmatrix}0 \\\\ 1 \\\\ -1\\end{bmatrix}$ and $y=\\begin{bmatrix}1 \\\\ 0 \\\\ -1\\end{bmatrix}$.\n",
    "\n",
    "\\begin{align*}\n",
    "0\\times \\begin{bmatrix}1 \\\\ 1 \\\\ 1\\end{bmatrix} + 1 \\times \\begin{bmatrix}1 \\\\ 1 \\\\ 1\\end{bmatrix} - 1 \\times \\begin{bmatrix}1 \\\\ 1 \\\\ 1\\end{bmatrix} &= \\begin{bmatrix}0 \\\\ 0 \\\\ 0\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "Any other solutions are linear combinations of the first two independent vectors $x$ and $y$. \n",
    "\n",
    "#### Problem I.1.5\n",
    "\n",
    "* (a) let $z=\\begin{bmatrix}z_1\\\\z_2\\\\z_3\\end{bmatrix}$, and for every linear combination of $v$ and $w$, i.e. $cv+dw$, we let $(cv+dw)^Tz = 0$, so we have\n",
    "\n",
    "\\begin{align*}\n",
    "(cv+dw)^Tz &= cv^Tz + dw^Tz\\\\\n",
    "&= c(z_1 + z_2) + d(z_2 + z_3)\\\\\n",
    "&= cz_1 + (c+d)z_2 + dz_3\\\\\n",
    "&= 0\n",
    "\\end{align*}\n",
    "\n",
    "Solve this for any $c$ and $d$, we see that $z=\\begin{bmatrix}-1\\\\1\\\\-1\\end{bmatrix}$ solves the equation.\n",
    "\n",
    "* (b) We see that $cv+dw = \\begin{bmatrix}c\\\\c+d\\\\d\\end{bmatrix}$, it's easy to see that $u=\\begin{bmatrix}1\\\\3\\\\1\\end{bmatrix}$ is not on theplane, and we have $u^Tz = \\begin{bmatrix}1 &3&1\\end{bmatrix}\\begin{bmatrix}-1\\\\1\\\\-1\\end{bmatrix} = 1 \\ne 0$\n",
    "\n",
    "#### Problem I.1.6\n",
    "\n",
    "Let the corners of the parallelogram are: $A=(1,1)$,  $B=(1,3)$, $C=(4,2)$, the fourth corner is $D$. There are three possible values for $D$:\n",
    "* If $BC = AD$, then $D = A + AD = A + BC = A + (C-B) = (1,1)+(3,-1) = (4,0)$.\n",
    "* If $BD=AC$, then $D = B + BD = B + AC =  B + (C-A) = (4,2) + (3, 1) = (7, 3)$\n",
    "* If $AD=CB$, then $D = A + AD = A + CB = A + (B-C) = (1,1) + (-3,1) = (-2, 2)$\n",
    "\n",
    "#### Problem I.1.7\n",
    "\n",
    "$A=\\begin{bmatrix}v & w & v + 2w\\end{bmatrix}$, the column space is a plane defined by the combination of vectors $v$ and $w$, i.e. $cv+dw$.\n",
    "\n",
    "Now compute the nullspace of $A$, we let $Ax=0$, that is\n",
    "\n",
    "\\begin{align*}\n",
    "Ax &= \\begin{bmatrix}v & w & v + 2w\\end{bmatrix}\\begin{bmatrix}x_1\\\\x_2\\\\x_3\\end{bmatrix}\\\\\n",
    "&= x_1v + x_2 w + x_3 (v+2w)\\\\\n",
    "&= (x_1 + x_3)v + (x_2 + 2x_3)w\\\\\n",
    "&= 0\n",
    "\\end{align*}\n",
    "\n",
    "The solution is thus $x=\\begin{bmatrix}x_1\\\\2x_1\\\\-x_1\\end{bmatrix}$ and the nullspace of $A$ is the line defined by $x$. \n",
    "\n",
    "It's easy to see that the dimension of column space + dimension of null space = number of columns in $A$.\n",
    "\n",
    "#### Problem I.1.8\n",
    "\n",
    "Since $A_{ij}=j^2$, so we have $A=\\begin{bmatrix}1&4&9\\\\1&4&9\\\\1&4&9\\end{bmatrix}$, we see that $C=\\begin{bmatrix}1\\\\1\\\\1\\end{bmatrix}$, because the other two columns are just multiplier of this one. It's easy to see that $R=\\begin{bmatrix}1 & 4 & 9\\end{bmatrix}$\n",
    "\n",
    "#### Problem I.1.9\n",
    "\n",
    "If the column space space of an $m$ by $n$ matrix is all of $R^3$, then the dimension of column space is 3, i.e. the rank $r=3$. Also because the dimension of the column space is less or equal to the number of columns, we have $m\\ge 3$. Also we know that column rank = row rank, so we also have $n\\ge 3$.\n",
    "\n",
    "#### Problem I.1.10\n",
    "\n",
    "* For $A_1$, we have $C_1=\\begin{bmatrix}1 \\\\ 3 \\\\ 2\\end{bmatrix}$ because the other two columns are multiple of the first column. \n",
    "* Fro $A_2$, we have $C_2= \\begin{bmatrix}1 & 2\\\\ 4 &5\\\\ 7 & 8\\end{bmatrix}$ because the third column is $-1$ multiply first column plus 2 multiply the second column.\n",
    "\n",
    "#### Problem I.1.11\n",
    "\n",
    "* $A_1 = \\begin{bmatrix}1 \\\\ 3 \\\\ 2\\end{bmatrix}\\begin{bmatrix}1 & 3 & -2\\end{bmatrix}$\n",
    "\n",
    "* $A_2 = \\begin{bmatrix}1 & 2\\\\ 4 &5\\\\ 7 & 8\\end{bmatrix}\\begin{bmatrix}1 & 0 & -1\\\\ 0 &1 &2\\end{bmatrix}$\n",
    "\n",
    "#### Problem I.1.12\n",
    "\n",
    "* The basis for $A_1$ are columns in $C_1$ and the basis for $A_2$ are columns in $C_2$.\n",
    "* The dimension of column space for $A_1$ is 1, for $A_2$ is 2.\n",
    "* The rank of $A_1$ is 1, for $A_2$ is 2.\n",
    "* There are 1 independent row in $A_1$, and 2 independent rows in $A_2$.\n",
    "\n",
    "#### Problem I.1.13\n",
    "\n",
    "Let $A=\\begin{bmatrix}1 &0 & 1 &1 \\\\ 0 & 1 & 1 & -1 \\\\ 0 &0 & 0 &0 \\\\ 0&0&0&0\\end{bmatrix}$, $A$ has a rank of $2$. \n",
    "\n",
    "$C$ has dimension $4\\times 2$, and $R$ has a dimension of $2\\times 4$.\n",
    "\n",
    "#### Problem I.1.14\n",
    "\n",
    "* (a) We just need to give an example of two matrices $A$ and $B$ that have the same column space but different row spaces.\n",
    "Consider vectors in $R^2$, let $A=\\begin{bmatrix}1 &2 \\\\ 1 & 2\\end{bmatrix}$, and $B=\\begin{bmatrix}2 &1 \\\\ 2 & 1\\end{bmatrix}$. Their column spaces are the same, i.e. the line $x\\begin{bmatrix}1 \\\\ 1\\end{bmatrix}$. \n",
    "\n",
    "If we write them in $A=CR$ format, we have $A=\\begin{bmatrix}1\\\\1\\end{bmatrix}\\begin{bmatrix}1 & 2 \\end{bmatrix}$ and  $B =\\begin{bmatrix}1\\\\1\\end{bmatrix}\\begin{bmatrix}2 & 1 \\end{bmatrix}$, we can see that the row space of $A$ is line $x\\begin{bmatrix}1 & 2 \\end{bmatrix}$, whic is different from the row space of $B$ is line $\\begin{bmatrix}2 & 1 \\end{bmatrix}$.\n",
    "\n",
    "* (b) The matrix $C$ for $A$ is $\\begin{bmatrix}1\\\\1\\end{bmatrix}$, while it is $\\begin{bmatrix}2\\\\2\\end{bmatrix}$ for $B$.\n",
    "\n",
    "* (c) $A$ and $B$ have the same rank because their column spaces are the same.\n",
    "\n",
    "#### Problem I.1.15\n",
    "\n",
    "If $A=CR$, the first row of $A$ is a combination of the rows of $R$, each element of the first row in $C$ corresponds to the coefficient to each row in $R$. That is, $C_{11}$ multiply row 1 of $R$, $C_{12}$ multiply row 2 of $R$, etc. and the sum of these products are the first row of $A$.\n",
    "\n",
    "#### Problem I.1.16\n",
    "\n",
    "The rows of $R$ are a basis for the row space of $A$, this means that for any vector in the row space of $A$, it is a linear combination of the row vectors in $R$. The row vectors in $R$ are independent as well.\n",
    "\n",
    "#### Problem I.1.17\n",
    "\n",
    "* $A_1 = C_1R_1 = \\begin{bmatrix}0 & 1\\\\0 & 1 \\\\ 1 & 1 \\\\ 1 & 1\\end{bmatrix}\\begin{bmatrix}1 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 1\\end{bmatrix}$\n",
    "\n",
    "* $A_2 = C_2R_2 = \\begin{bmatrix}A_1 \\\\ A_1 \\end{bmatrix} = \\begin{bmatrix}C_1R_1 \\\\ C_1R_1 \\end{bmatrix} = \\begin{bmatrix}C_1 \\\\ C_1 \\end{bmatrix}R_1$. So $C_2 = \\begin{bmatrix}C_1 \\\\ C_1 \\end{bmatrix}$ and $R_2=R_1$.\n",
    "\n",
    "* $A_3 = C_3R_3 = \\begin{bmatrix}A_1 &A_1 \\\\ A_1 & A_1 \\end{bmatrix} = \\begin{bmatrix}C_1R_1 & C_1R_1 \\\\ C_1R_1 & C_1R_1\\end{bmatrix} = \\begin{bmatrix}C_1 \\\\ C_1 \\end{bmatrix}\\begin{bmatrix}R_1 & R_1\\end{bmatrix}$\n",
    "So $C_3 = \\begin{bmatrix}C_1 \\\\ C_1 \\end{bmatrix}$ and $R_3 = \\begin{bmatrix}R_1 & R_1\\end{bmatrix}$\n",
    "\n",
    "All matrices have $rank=2$\n",
    "\n",
    "#### Problem I.1.18\n",
    "\n",
    "\\begin{align*}\n",
    "\\begin{bmatrix}\n",
    "0 & A\\\\\n",
    "0 & A\\\\\n",
    "\\end{bmatrix} &= \\begin{bmatrix}\n",
    "0 & CR \\\\\n",
    "0 & CR\\\\\n",
    "\\end{bmatrix} \\\\ \n",
    "&= \\begin{bmatrix}\n",
    "C \\\\\n",
    "C\\\\\n",
    "\\end{bmatrix}\\begin{bmatrix}\n",
    "0 & R \\\\\n",
    "0 & R \\\\\n",
    "\\end{bmatrix}\n",
    "\\end{align*}\n",
    "\n",
    "#### Problem I.1.19\n",
    "\n",
    "\\begin{align*}\n",
    "A &= \\begin{bmatrix}\n",
    "1 & 3 & 8 \\\\\n",
    "1 & 2 & 6 \\\\\n",
    "0 & 1 & 2 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix}\n",
    "1 & 3 & 8 \\\\\n",
    "0 & -1 & -2 \\\\\n",
    "0 & 1 & 2 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix}\n",
    "1 & 3 & 8 \\\\\n",
    "0 & -1 & -2 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix}\n",
    "1 & 0 & 2 \\\\\n",
    "0 & -1 & -2 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "&= \\begin{bmatrix}\n",
    "1 & 0 & 2 \\\\\n",
    "0 & 1 & 2 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}\\\\\n",
    "&= \\text{rref}(A)\\\\\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem I.1.20\n",
    "\n",
    "We have $C=\\begin{bmatrix}2\\\\3\\end{bmatrix}$, $R=\\begin{bmatrix}2 & 4 \\end{bmatrix}$, so $C^TC= \\begin{bmatrix}2&3\\end{bmatrix}\\begin{bmatrix}2\\\\3\\end{bmatrix} = 13$, and $RR^T=\\begin{bmatrix}2&4\\end{bmatrix}\\begin{bmatrix}2\\\\4\\end{bmatrix} = 20$, $C^TAR^T = \\begin{bmatrix}2&3\\end{bmatrix}\\begin{bmatrix}2&4\\\\3&6\\end{bmatrix}\\begin{bmatrix}2\\\\4\\end{bmatrix}=130$\n",
    "\n",
    "\n",
    "Then we get $M=(C^TC)^{-1}(C^TAR^T)(RR^T)^{-1} = \\frac{1}{13}130\\frac{1}{20}=\\frac{1}{2}$\n",
    "\n",
    "#### Problem I.1.21\n",
    "\n",
    "We have $C=\\begin{bmatrix}1&3\\\\1&2\\\\0&1\\end{bmatrix}$ and $R=\\begin{bmatrix}1&3&8\\\\1&2&6\\end{bmatrix}$, and compute $(C^TC)^{-1}=\\frac{1}{16}\\begin{bmatrix}13&-5\\\\-5&2\\end{bmatrix}$, and $(RR^T)^{-1} = \\frac{1}{9}\\begin{bmatrix}41&-55\\\\-55&74\\end{bmatrix} $\n",
    "\n",
    "Also $C^TAR^T = \\begin{bmatrix}129&96\\\\351&261\\end{bmatrix}$\n",
    "\n",
    "So we have $M=(C^TC)^{-1}(C^TAR^T)(RR^T)^{-1} = \\begin{bmatrix}-\\frac{7}{16}&\\frac{1}{2}\\\\\\frac{3}{16}&-\\frac{3}{16}\\end{bmatrix}$\n",
    "\n",
    "#### Problem I.1.22\n",
    "\n",
    "If we have $\\begin{bmatrix}b\\\\d\\end{bmatrix}=m\\begin{bmatrix}a\\\\c\\end{bmatrix}$, then $ad-bc = amc - mac = 0$, then the inversion of 2x2 matrix doesn't exist.\n",
    "\n",
    "#### Problem I.1.23\n",
    "\n",
    "We pick $A=\\begin{bmatrix}1 &2\\\\2&4\\\\3&6\\end{bmatrix}$, then we have $A=CR=\\begin{bmatrix}1\\\\2\\\\3\\end{bmatrix}\\begin{bmatrix}1&2\\end{bmatrix}$. \n",
    "\n",
    "Then we have $(C^TC)^{-1} = \\frac{1}{14}$, and pick $R=\\begin{bmatrix}1&2\\end{bmatrix}$, so $(RR^T)^{-1} = \\frac{1}{5}$\n",
    "and $C^TAR^T = 70$, so we have $M= \\begin{bmatrix}1\\end{bmatrix}$\n",
    "\n",
    "#### Problem I.1.24\n",
    "\n",
    "We pick $A=\\begin{bmatrix}1 &3\\\\2&5\\\\3&6\\end{bmatrix}$, then we have $A=CR=\\begin{bmatrix}1 &3\\\\2&5\\\\3&6\\end{bmatrix}I$. \n",
    "\n",
    "and pick $R=\\begin{bmatrix}1&3\\\\2&5\\end{bmatrix}$, so we have $M= \\begin{bmatrix}-8&11\\\\-15&23\\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 3.68421053, -1.63157895],\n",
       "        [-1.63157895,  0.73684211]]), array([[ 29., -17.],\n",
       "        [-17.,  10.]]), array([[ 8969, 15334],\n",
       "        [20187, 34513]]), array([[ -8.,  11.],\n",
       "        [-15.,  23.]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#C = np.array([1,2,3]).reshape(3,1)\n",
    "R = np.array([[1, 3], [2,5]])#.reshape(1,2)\n",
    "A = np.array([[1,3],[2,5],[3,6]])\n",
    "C = A\n",
    "\n",
    "a = np.matmul(C.transpose(), A)\n",
    "b = np.matmul(a, R.transpose())\n",
    "k = np.matmul(C.transpose(), C)\n",
    "invc = np.linalg.inv(k)\n",
    "invr = np.linalg.inv(np.matmul(R, R.transpose()))\n",
    "m = np.matmul(a, b)\n",
    "f = np.matmul(invc, m)\n",
    "f = np.matmul(f, invr)\n",
    "invc, invr, m, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem I.2.1\n",
    "\n",
    "$AB=A\\begin{bmatrix}x & y\\end{bmatrix}=\\begin{bmatrix}0 & 0\\end{bmatrix}$. So If $A$ is $m$ by $n$, then $B$ is $n$ by $2$, and $C$ is $m$ by $2$.\n",
    "\n",
    "#### Problem I.2.2\n",
    "Yes, you can multiply $a$ times $b^T$, the shape of the answer $ab^T$ is $m$ by $p$. The number is row $i$, column $j$ of $ab^T$ is $a_ib_j$\n",
    "\n",
    "$aa^T$ is symmetric with the diagonal elements the squares of the elements in $a$. \n",
    "\n",
    "#### Problem I.2.3\n",
    "\n",
    "* (a) Sum of rank on formula for the matrix-matrix product $AB$\n",
    "\n",
    "$AB=\\sum^n_{j=1} a_jb^T_j$\n",
    "\n",
    "* (b) $c_{ij} = \\sum^n_{k=1} a_{ki}b_{kj}$\n",
    "\n",
    "#### Problem I.2.4\n",
    "\n",
    "If $B$ has only 1 column, $AB=\\sum^n_{j=1} a_jb_j$ where $b_j$ is a number. The $m$ by $1$ column vector $AB$ is a combination of the columns in $A$.\n",
    "\n",
    "#### Problem I.2.5\n",
    "\n",
    "$(AB)C = \\begin{bmatrix}b_1+ab_3 & b_2+ab_4\\\\b_3 & b_4\\end{bmatrix}\\begin{bmatrix}1 &0 \\\\ c& 1\\end{bmatrix} = \\begin{bmatrix}b_1+ab_3+cb_2+acb_4 & b_2+ab_4\\\\b_3 +cb_4& b_4\\end{bmatrix}$\n",
    "\n",
    "$A(BC) = \\begin{bmatrix}1 & a\\\\0 & 1\\end{bmatrix}\\begin{bmatrix}b_1+cb_2 & b_2\\\\b_3+cb_4 & b_4\\end{bmatrix} = \\begin{bmatrix}b_1+ab_3+cb_2+acb_4 & b_2+ab_4\\\\b_3 +cb_4& b_4\\end{bmatrix}$\n",
    "\n",
    "So we verified $(AB)C=A(BC)$\n",
    "\n",
    "#### Problem I.2.6\n",
    "If $B=I$, then the rank-one matrices $a_1b^*_1 = \\begin{bmatrix}a_1 & 0 & 0\\end{bmatrix}$, $a_2b^*_2 = \\begin{bmatrix}0 & a_2 & 0 \\end{bmatrix}$ and $a_3b^*_3 = \\begin{bmatrix}0 & 0 & a_3 \\end{bmatrix}$, they add up to $AI=A$.\n",
    "\n",
    "#### Problem I.2.7\n",
    "\n",
    "Example of $A$ and $B$ for which $AB$ has a smaller column space than $A$. \n",
    "Let $A=\\begin{bmatrix}1 & 4\\\\2 & 5 \\\\3 & 6\\end{bmatrix}$, it has a column space of dimension 2, and $B=\\begin{bmatrix}1 \\\\ 0\\end{bmatrix}$, then $AB=\\begin{bmatrix}1 \\\\ 2 \\\\ 3\\end{bmatrix}$, which is clearly has a column space of dimension 1, and is smaller than $A$.\n",
    "\n",
    "#### Problem I.2.8\n",
    "\n",
    "To get columns times rows, we do: \n",
    "\n",
    "* (1) For $k=1$ to $n$\n",
    "* (2) For $i=1$ to $m$\n",
    "* (3) For $j=1$ to $p$\n",
    "* (4) $C(i,j) = C(i,j) + A(i,k)B(k,j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.],\n",
       "       [26.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Test the multiplication of columns times rows\n",
    "\n",
    "#### Test cases\n",
    "a = np.array([1,2])\n",
    "b = np.array([3,4])\n",
    "my_outer = mat.outer_product(a, b)\n",
    "np_outer = np.outer(a,b)\n",
    "assert(np.array_equal(my_outer, np_outer))\n",
    "\n",
    "A = np.array([[1,2],[3,4]])\n",
    "B = np.array([[2,1],[5,6]])\n",
    "np_prod = np.matmul(A, B)\n",
    "my_prod_outer = mat.columns_times_rows_outer(A, B)\n",
    "my_prod_rc = mat.rows_times_columns(A, B)\n",
    "my_prod_cr = mat.columns_times_rows(A, B)\n",
    "assert(np.array_equal(my_prod_outer, np_prod))\n",
    "assert(np.array_equal(my_prod_rc, np_prod))\n",
    "assert(np.array_equal(my_prod_cr, np_prod))\n",
    "\n",
    "A = np.array([[1,2],[3,4]])\n",
    "B = np.array([[2],[5]])\n",
    "mat.columns_times_rows(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem I.3.1\n",
    "\n",
    "For any vector $x$ in the nullspace of $B$, we have $Bx=0$, so we also have $ABx=A0=0$, so $x$ is also in the nullspace of $AB$. We showed that the nullspace of $AB$ contains the nullspace of $B$.\n",
    "\n",
    "#### Problem I.3.2\n",
    "\n",
    "We choose $A=\\begin{bmatrix}-4 &-8 \\\\ 2 & 4\\end{bmatrix}$, so $A^2 = \\begin{bmatrix}0 &0 \\\\ 0 & 0\\end{bmatrix}$. \n",
    "We have $\\text{rank}(A)=1$, $\\text{rank}(A^2)=0 \\lt \\text{rank}(A)$.\n",
    "We also can prove that $A^TA=\\begin{bmatrix}20 &40 \\\\ 40 & 80\\end{bmatrix}$, so we see that $rank(A^TA)=rank(A)$.\n",
    "You can find such $A$ by making assumptions on its columns and the columns of $A^2$.\n",
    "\n",
    "#### Problem I.3.3\n",
    "\n",
    "If $x$ belongs to the nullspace of $C$, then we have $Cx=\\begin{bmatrix}A\\\\B\\end{bmatrix}x=\\begin{bmatrix}Ax\\\\Bx\\end{bmatrix}=0$ so it makes $Ax=0$ and $Bx=0$ at the same time. So the $x$ belongs to both the nullspace of $A$ and $B$. \n",
    "\n",
    "The opposite is also true, i.e. if $x$ belongs to both the nullspace of $A$ and $B$, it also belongs to the nullspace of $C$. \n",
    "So we conclude that the nullspace of $C$ is the intersection of the nullspaces of $A$ and $B$.\n",
    "\n",
    "#### Problem I.3.4\n",
    "\n",
    "Suppose for matrix $A$, its rank is $r$, since $N(A)=N(A^T)$, we know that the dimension of $N(A)$ and $N(A^T)$ spaces are equal, i.e. $m-r=n-r$, so we have $m=n$, $A$ is a square matrix. \n",
    "\n",
    "For any given vector $x$ in the nullspace $N(A)$, it is also in the left-nullspace $N(A^T)$, so we have $Ax=0$ and $A^Tx=0$, combine both equations, we have $(A-A^T)x=0$, so unless $x$ is zero, we have $A=A^T$. So if the nullspace has dimension $>0$, we can say $A$ is symmetric. \n",
    "\n",
    "If, however, the nullspace of $A$ has dimension 0, i.e. $r=m=n$, then we may not have a symmetric matrix $A$. \n",
    "\n",
    "For example, let $A=\\begin{bmatrix}1&3\\\\2&4\\end{bmatrix}$, this matrix has a rank of 2, and row space = column space, since both span the full $R^2$ plane, but clearly, $A$ is not symmetric.\n",
    "\n",
    "#### Problem I.3.5\n",
    "\n",
    "* $r=m=n$, $A_1=\\begin{bmatrix}1&3\\\\2&4\\end{bmatrix}$. $A_1$ is invertible, so $A_1x=b$ has 1 solution for every $b$. Or we can say that the column space is the full $R^2$, so for every $b$ in $R^2$, it's in the column space, and we have a solution.\n",
    "\n",
    "* $r=m<n$, $A_2=\\begin{bmatrix}1&2&3\\\\2&4&1\\end{bmatrix}$, since the column 1 and column 2 are dependent, we have $\\text{rank}(A_2)=m = 2$. For $A_2x=b$, we have two equations and 3 unknowns, which generally gives us infinitely many solutions. Or we can say that the column space is $R^2$ in $R^2$, so every $b$ from $R^2$ is in the column space and we always have a solution corresponding to the basis matrix. Since column 2 is a multiple of column 1, there are infinitely many solutions. \n",
    "However, if one of the columns is 0, e.g. $A_2=\\begin{bmatrix}0&2&3\\\\0&4&1\\end{bmatrix}$, we still have $rank(A_2)=2$, but there's only one solution for $A_2x=b$ now.\n",
    "* $r=n<m$, $A_3=\\begin{bmatrix}1&3\\\\2&4\\\\3&6\\end{bmatrix}$, so $rank(A_3)=2$, for $A_3x=b$, If $b$ is in the column space. For example, $b=\\begin{bmatrix}4\\\\6\\\\9\\end{bmatrix}$, we'll have a solution, but if $b$ is not in the column space, there's no solution.\n",
    "* $r<m,r<n$, $A_4=\\begin{bmatrix}1&2\\\\2&4\\\\3&6\\end{bmatrix}$, $rank(A_4)=1 < m, n$. for $A_4x=b$, we have 3 equations and 1 unknown. If $b$ is in the column space (a line along $\\begin{bmatrix}1\\\\2\\\\3\\end{bmatrix}$), we have infinitely many solutions, otherwise there's no solution at all.\n",
    "\n",
    "#### Problem I.3.6\n",
    "\n",
    "If $Ax$ equals zero, then $A^TAx=0$ as well. This shows that every vector in the $N(A)$ is also in $N(A^TA)$, so we have $N(A)\\subset N(A^TA)$. \n",
    "\n",
    "On the other hand, if $A^TAx=0$, then $x^TA^TAx=0$, i.e. $\\|Ax\\|^2=0$ and we see $Ax=0$, so if a vector is in $N(A^TA)$, it's also in $N(A)$, and we have $N(A^TA) \\subset N(A)$. \n",
    "\n",
    "We conclude from above that $N(A)=N(A^TA)$, i.e. $A^TA$ has the same nullspace as $A$.\n",
    "\n",
    "#### Problem I.3.7\n",
    "\n",
    "From problem I.3.2, we see that for a square matrix, we can have the case that $rank(A^2)\\lt rank(A)$, since the dimension of nullspace is $n-r$, so the dimensions of nullspace between $A^2$ and $A$ can be different, and the nullspaces can of course be different.\n",
    "\n",
    "#### Problem I.3.8\n",
    "\n",
    "We have $A=\\begin{bmatrix}0&1\\\\0 &0\\end{bmatrix}$, it's easy to see that $C=\\begin{bmatrix}1\\\\0\\end{bmatrix}$ and let $Ax=0$, and solve for $x$, we have $x=\\begin{bmatrix}c\\\\0\\end{bmatrix}$, where $c$ is any number. It's clear that the column space and nullspace are the same in such case.\n",
    "\n",
    "#### Problem I.3.9\n",
    "\n",
    "$A=\\begin{bmatrix}-1&1&0&0&0\\\\0&-1&1&0&0\\\\0&0&1&-1&0\\\\1&0&0&-1&0\\\\1&0&0&0&-1\\\\0&1&0&0&-1\\\\0&0&1&0&-1\\\\0&0&0&1&-1\\end{bmatrix}$\n",
    "\n",
    "One vector in $N(A)$ is $\\begin{bmatrix}1\\\\1\\\\1\\\\1\\\\1\\end{bmatrix}$\n",
    "\n",
    "The four independent vectors in $N(A^T)$ are identified from the four loops in the graph:\n",
    "\n",
    "$v_1=\\begin{bmatrix}-1\\\\0\\\\0\\\\0\\\\-1\\\\1\\\\0\\\\0\\end{bmatrix}$\n",
    "$v_2=\\begin{bmatrix}0\\\\-1\\\\0\\\\0\\\\0\\\\-1\\\\1\\\\0\\end{bmatrix}$\n",
    "$v_3=\\begin{bmatrix}0\\\\0\\\\1\\\\0\\\\0\\\\0\\\\-1\\\\1\\end{bmatrix}$\n",
    "$v_4=\\begin{bmatrix}0\\\\0\\\\0\\\\-1\\\\1\\\\0\\\\0\\\\-1\\end{bmatrix}$\n",
    "\n",
    "#### Problem I.3.10 \n",
    "\n",
    "If $N(A)$ is zero vector, the for $B=\\begin{bmatrix}A&A&A\\end{bmatrix}$, its nullspace is also zero vector, since for $Bx=0$, we need to make $\\begin{bmatrix}Ax&Ax&Ax\\end{bmatrix}=0$, which dictates each $Ax=0$, which has only zero solution. So the $N(B)$ is also zero vector.\n",
    "\n",
    "#### Problem I.3.11\n",
    "\n",
    "* (i) $S\\cap T$: the possible dimension is 7 if $S \\subset T$, or 0 if no such vector exists. \n",
    "* (ii) $S+T$: 7 if $S \\subset T$, 8,9 if there's vector in $S$ but not in $T$.\n",
    "If we think about matrices $A$ and $B$, both with 10 rows. If $rank(A)=2$ and $rank(B)=7$, then $A$'s column space is a dimension 2 subspace in $R^{10}$, and $B$'s column space is dimension 7 subspace in $R^{10}$. So for $Ax$ and $By$ are vectors in subspaces $S$ and $T$ separately. Then $Ax+By=\\begin{bmatrix}A&B\\end{bmatrix}\\begin{bmatrix}x\\\\y\\end{bmatrix}$ is a vector of $s+t$. So we need find the column space of $\\begin{bmatrix}A&B\\end{bmatrix}$. The maximum number of independent columns is thus 9, and minimum number of independent columns is 7. \n",
    "* (iii) All vectors in $R^{10}$ that are perpendicular to every vector in $S$: If we think about $S$ as column space in $R^{10}$, the space that perpendicular to a column space is the left nullspace, whose dimension is $m-r=10-2=8$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem I.4.1\n",
    "\n",
    "$A=\\begin{bmatrix}2 &1 \\\\6 & 7\\end{bmatrix}=\\begin{bmatrix}1 &0 \\\\3 & 1\\end{bmatrix}\\begin{bmatrix}2 &1 \\\\0 & 4\\end{bmatrix}$\n",
    "\n",
    "$A=\\begin{bmatrix}1 &1 &1\\\\1 & 1 &1 \\\\ 1 & 1 & 1\\end{bmatrix}=\\begin{bmatrix}1 &0 &0 \\\\1 & 1 & 0\\\\1 &0 & 1\\end{bmatrix}\\begin{bmatrix}1 &1 &1 \\\\0 & 0 &0 \\\\ 0 & 0 &0\\end{bmatrix}$\n",
    "\n",
    "$A=\\begin{bmatrix}2 &-1 &0\\\\-1 & 2 &-1 \\\\ 0& -1 & 2\\end{bmatrix}=\\begin{bmatrix}1 &0 &0 \\\\-\\frac{1}{2} & 1 & 0\\\\0 &-\\frac{2}{3} & 1\\end{bmatrix}\\begin{bmatrix}2 &-1 &0 \\\\0 & \\frac{3}{2} &-1 \\\\ 0 & 0 &\\frac{4}{3}\\end{bmatrix}$\n",
    "\n",
    "#### Problem I.4.2\n",
    "\n",
    "Suppose the rank-1 matrix $A$ is created by two vectors: $xy^T$, so we have for row $i$ and column $j$, $a_{ij} = x_iy_j$. Since we know $a_{11},\\dots, a_{1n}$ and $a_{11}, \\dots, a_{m1}$, so if we assume $x_1$ is known, then it's easy to see that $y_{j} = \\frac{a_{1j}}{x_1}$ and $x_{i} = \\frac{a_{i1}}{y_1}=\\frac{a_{i1}x_1}{a_{11}}$. In the end, we have $a_{ij} = \\frac{a_{i1}a_{1j}}{a_{11}}$.\n",
    "\n",
    "\n",
    "For $a_{11}=2$, $a_{12}=3$, $a_{21}=4$, we have $a_{22}=\\frac{a_{21}a_{12}}{a_{11}}=6$. \n",
    "\n",
    "This formula breaks down when $x_1=0$, i.e. $a_{11}, \\dots, a_{1n}$ are all zeros. The same happens when $y_1=0$. Then rank 1 is impossible (when both are zeros) or not unique.\n",
    "\n",
    "#### Problem I.4.3\n",
    "\n",
    "Notice that when we apply 'elimination' process on a matrix $A$, at the end of the process, it becomes an upper triangular matrix. So we can search for matrices that when left multiply the $A$, they reduce the $A$ to $U$. We look for one matrix for each step in an 'elimination' process. \n",
    "\n",
    "Suppose $A$ is $n$ by $n$ matrix. The first step is to transform the first elements of all rows except the first row to be zeros. We achieve this by multiply a number to the first row and subtract from each row below. Represented by a left multiply matrix, we have\n",
    "\n",
    "$E_1 = \\begin{bmatrix}1 &0 &\\dots &0\\\\-l_{21} & 1 &\\dots &0 \\\\ -l_{31} & 0 & 1 & \\dots\\\\\\dots& \\dots & \\dots & \\dots \\\\ -l_{n1} & 0 & \\dots & 1\\end{bmatrix}$\n",
    "\n",
    "Now apply step 2 of 'elimination' to change all the second elements for rows below the second row to zero, we have \n",
    "$E_2 = \\begin{bmatrix}1 &0 &\\dots &0\\\\0 & 1 & \\dots &0 \\\\ 0 & -l_{32} & 1 & 0\\\\\\dots& \\dots & \\dots & \\dots \\\\ 0 & -l_{n2} & \\dots & 1\\end{bmatrix}$\n",
    "\n",
    "Continue this until we have \n",
    "$E_{n-1} = \\begin{bmatrix}1 &0 &\\dots &0\\\\0 & 1 & \\dots &0 \\\\ 0 & 0 & 1 & 0\\\\\\dots& \\dots & \\dots & \\dots \\\\ 0 & \\dots & -l_{n,n-1} & 1\\end{bmatrix}$\n",
    "\n",
    "Now it's clear that $E=E_{n-1}\\dots E_{2}E_{1}$.\n",
    "\n",
    "For $A=\\begin{bmatrix}2 &1 &0\\\\0 & 4 &2 \\\\ 6 & 3 & 5\\end{bmatrix}$, we have $n=3$, so \n",
    "$E_1 = \\begin{bmatrix}1 &0 &0\\\\-l_{21} & 1 &0 \\\\ -l_{31} & 0 & 1\\end{bmatrix}$\n",
    "and \n",
    "$E_2 = \\begin{bmatrix}1 &0 &0\\\\0 & 1 & 0 \\\\ 0 & -l_{32} & 1\\end{bmatrix}$\n",
    "\n",
    "so $E=E_2E_1 = \\begin{bmatrix}1 &0 &0\\\\-l_{21} & 1 & 0 \\\\ -l_{31}+l_{21}l_{32} & -l_{32} & 1\\end{bmatrix}=\\begin{bmatrix}1 &0 &0\\\\0 & 1 & 0 \\\\ -3 & 0 & 1\\end{bmatrix}$\n",
    "\n",
    "And $L=E^{-1} = \\begin{bmatrix}1 &0 &0 \\\\0 & 1 & 0\\\\3 &0 & 1\\end{bmatrix}$\n",
    "\n",
    "$A=\\begin{bmatrix}2 &1 &0\\\\0 & 4 &2 \\\\ 6 & 3 & 5\\end{bmatrix}=\\begin{bmatrix}1 &0 &0 \\\\0 & 1 & 0\\\\3 &0 & 1\\end{bmatrix}\\begin{bmatrix}2 &1 &0 \\\\0 & 4 &2 \\\\ 0 & 0 &5\\end{bmatrix}$ï¼Œ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem I.4.4\n",
    "\n",
    "* (a) $E=E_2E_1=\\begin{bmatrix}1 & 0 & 0\\\\ -a & 1 & 0 \\\\ ac -b & -c & 1\\end{bmatrix}$, and we have \n",
    "$EA = I$.\n",
    "\n",
    "* (b) $E^{-1}_1 = \\begin{bmatrix}1 & 0 & 0\\\\ a & 1 & 0 \\\\ b & 0 & 1\\end{bmatrix}$ and $E^{-1}_2 = \\begin{bmatrix}1 & 0 & 0\\\\ 0 & 1 & 0 \\\\ 0 & c & 1\\end{bmatrix}$\n",
    "\n",
    "So $L=E^{-1}_1E^{-1}_2 =\\begin{bmatrix}1 & 0 & 0\\\\ a & 1 & 0 \\\\ b & c & 1\\end{bmatrix} = A$\n",
    "\n",
    "We notice that the multipliers $a$, $b$, $c$ are mixed up in $E=L^{-1}$ but  they are perfect in $L$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem I.4.5\n",
    "\n",
    "$\\begin{bmatrix}1 & 0 \\\\ l & 1\\end{bmatrix}\\begin{bmatrix}d & e \\\\ 0 & f\\end{bmatrix} = \\begin{bmatrix}d & e \\\\ ld & le+f\\end{bmatrix} = \\begin{bmatrix}0 & 1 \\\\ 2 & 3\\end{bmatrix}$\n",
    "\n",
    "So we have $d=0$, $e=1$, but also $ld=0$, which doesn't equal to 2, and contradicts. \n",
    "\n",
    "$\\begin{bmatrix}1 & 0 & 0\\\\ l & 1 & 0 \\\\ m & n & 1\\end{bmatrix}\\begin{bmatrix}d & e & g\\\\ 0 & f & h \\\\ 0 & 0 & i\\end{bmatrix} = \\begin{bmatrix}d & e & g\\\\ ld & le+f & lg + h \\\\md & me + nf & mg + nh + i \\end{bmatrix} = \\begin{bmatrix}1 & 1 & 0 \\\\1& 1 & 2 \\\\1 & 2 & 1\\end{bmatrix}$\n",
    "\n",
    "We get $d=e=1$, and $g=0$, from $ld=1$, we have $l=1$, and from $lg+h=2$, we have $h=2$, and from $le+f=1$, we have $f=0$, from $md=1$, we have $m=1$, but then $me+nf = 1 + 0 = 1$ which doesn't equal to $2$, contradicts. \n",
    "\n",
    "#### Problem I.4.6\n",
    "\n",
    "To make zero in the second pivot position, $c = 2$, then $A=\\begin{bmatrix}1 & 2 & 0\\\\2 & 4 & 1 \\\\ 3 & 5 & 1\\end{bmatrix} \\rightarrow \\begin{bmatrix}1 & 2 & 0\\\\0 & 0 & 1 \\\\ 0 & -1 & 1\\end{bmatrix}$, we exchange row 2 and row 3 to get an upper triangular matrix $U$. \n",
    "\n",
    "However, when $c=1$, then $A=\\begin{bmatrix}1 & 1 & 0\\\\2 & 4 & 1 \\\\ 3 & 5 & 1\\end{bmatrix}\\rightarrow \\begin{bmatrix}1 & 1 & 0\\\\0 & 2 & 1 \\\\ 0 & 2 & 1\\end{bmatrix}\\rightarrow\\begin{bmatrix}1 & 1 & 0\\\\0 & 0 & 1 \\\\ 0 & 0 & 0\\end{bmatrix}$. It's clear that no row exchange can generate an upper triangular matrix with non-zero pivot elements.\n",
    "\n",
    "#### Problem I.4.7\n",
    "\n",
    "$A=\\begin{bmatrix}a & a & a & a\\\\a & b & b & b\\\\ a & b & c & c \\\\ a & b & c & d\\end{bmatrix}\\rightarrow\\begin{bmatrix}a & a & a & a\\\\0 & b-a & b-a & b-a\\\\ 0 & b-a & c-a & c-a \\\\ 0 & b-a & c-a & d-a\\end{bmatrix} \\rightarrow\\begin{bmatrix}a & a & a & a\\\\0 & b-a & b-a & b-a\\\\ 0 & 0 & c-b & c-b \\\\ 0 & 0 & c-b & d-b\\end{bmatrix}\\rightarrow\\begin{bmatrix}a & a & a & a\\\\0 & b-a & b-a & b-a\\\\ 0 & 0 & c-b & c-b \\\\ 0 & 0 & 0 & d-c\\end{bmatrix}$\n",
    "\n",
    "and we have $A=LU=\\begin{bmatrix}1 & 0 & 0 & 0\\\\1 & 1 & 0 & 0\\\\ 1 & 1 & 1 & 0 \\\\ 1 & 1 & 1 & 1\\end{bmatrix}\\begin{bmatrix}a & a & a & a\\\\0 & b-a & b-a & b-a\\\\ 0 & 0 & c-b & c-b \\\\ 0 & 0 & 0 & d-c\\end{bmatrix}$\n",
    "\n",
    "For $U$ with non-zero pivot, we need $a\\ne 0$, and $b\\ne a$, $c\\ne b$, $d\\ne c$.\n",
    "\n",
    "#### Problem I.4.8\n",
    "\n",
    "$A=\\begin{bmatrix}1 & 1 & 0 \\\\1 & 2 & 1\\\\ 0 & 1 & 2\\end{bmatrix} = LU= \\begin{bmatrix}1 & 0 & 0 \\\\1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{bmatrix}\\begin{bmatrix}1 & 1 & 0 \\\\0 & 1 & 1 \\\\ 0 & 0 & 1 \\end{bmatrix} = \\begin{bmatrix}1 & 0 & 0 \\\\1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{bmatrix}\\begin{bmatrix}1 & 0 & 0 \\\\0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}\\begin{bmatrix}1 & 1 & 0 \\\\0 & 1 & 1 \\\\ 0 & 0 & 1 \\end{bmatrix} = LDL^T$\n",
    "\n",
    "$A=\\begin{bmatrix}a & a & 0 \\\\a & a+b & b\\\\ 0 & b & b+c\\end{bmatrix} = LU= \\begin{bmatrix}1 & 0 & 0 \\\\1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{bmatrix}\\begin{bmatrix}a & a & 0 \\\\0 & b & b \\\\ 0 & 0 & c \\end{bmatrix} = \\begin{bmatrix}1 & 0 & 0 \\\\1 & 1 & 0 \\\\ 0 & 1 & 1 \\end{bmatrix}\\begin{bmatrix}a & 0 & 0 \\\\0 & b & 0 \\\\ 0 & 0 & c \\end{bmatrix}\\begin{bmatrix}1 & 1 & 0 \\\\0 & 1 & 1 \\\\ 0 & 0 & 1 \\end{bmatrix} = LDL^T$\n",
    "\n",
    "#### Problem I.4.9\n",
    "\n",
    "The pivots for the upper left 2 by 2 submatrix $A_2$ are 5 and 9.\n",
    "\n",
    "#### Problem I.4.10\n",
    "\n",
    "$A_k$ factors into $L_kU_k$\n",
    "\n",
    "#### Problem I.4.11\n",
    "\n",
    "$A=\\begin{bmatrix}1 &3 \\\\ 2 &4 \\end{bmatrix}=\\begin{bmatrix}\\frac{3}{4} \\\\ 1 \\end{bmatrix}\\begin{bmatrix}2 &4 \\end{bmatrix} + \\begin{bmatrix}-\\frac{1}{2} &0 \\\\ 0 &0 \\end{bmatrix} = \\begin{bmatrix}\\frac{3}{4} &1 \\\\ 1 &0 \\end{bmatrix}\\begin{bmatrix}2 &4 \\\\ -\\frac{1}{2} & 0 \\end{bmatrix}$\n",
    "\n",
    "$P_1AP_2 = LU = \\begin{bmatrix}1 & 0 \\\\ \\frac{3}{4} & 1 \\end{bmatrix}\\begin{bmatrix}4 &2 \\\\ 0 & -\\frac{1}{2} \\end{bmatrix}$\n",
    "\n",
    "#### Problem I.4.12\n",
    "\n",
    "If the short wide matrix $A$ has $m < n$, we put $0$ as the extra  column of $A$, then go with 'elimination'. Since $m < n$, we only do $m-1$ eliminations, so there are going to be $n-(m-1)=n-m+1$ non zero elements at the last row (excluding the b=0 column). since $n-m+1 > 1$, this means that there are non-zero solution to the equations. The nullspace dimension is thus at least $n-m$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem I.5.1\n",
    "\n",
    "If $u$ and $v$ are orthogonal unit vectors, then we have $(u+v)^T(u-v)=(u^T+v^T)(u-v)=u^Tu-u^Tv+vu^T-v^Tv= 1 + 0 - 0 - 1 = 0$, so $u+v$ is orthogonal to $u-v$. \n",
    "\n",
    "$|u+v|^2=(u+v)^T(u+v)=(u^T+v^T)(u+v)=u^Tu + u^Tv + v^Tu + v^Tv = 1 + 0 + 0 + 1 = 2$, so the length of vector $u+v$ is $\\sqrt{2}$. \n",
    "\n",
    "Similarly\n",
    "\n",
    "$|u-v|^2=(u-v)^T(u-v)=(u^T-v^T)(u-v)=u^Tu - u^Tv - v^Tu + v^Tv = 1 - 0 - 0 + 1 = 2$, so the length of vector $u-v$ is $\\sqrt{2}$. \n",
    "\n",
    "#### Problem I.5.2\n",
    "\n",
    "Note $u$ and $v$ are unit vectors. \n",
    "$u^Tw=u^T\\left(v-u(u^Tv)\\right)=u^Tv - u^Tu(u^Tv)=u^Tv - u^Tv = 0$\n",
    "\n",
    "#### Problem I.5.3\n",
    "\n",
    "$w^Tw + z^Tz = (u+v)^T(u+v) + (u-v)^T(u-v) = (u^T+v^T)(u+v) + (u^T-v^T)(u-v) = u^Tu + u^Tv + v^Tu + v^Tv + u^Tu - u^Tv - v^Tu + v^Tv = 2u^Tu + 2v^Tv$.\n",
    "\n",
    "#### Problem I.5.4\n",
    "Since $Q$ is orthogonal matrix, we have $Q^TQ=I$.\n",
    "\n",
    "$(Qx)^T(Qy) = x^TQ^TQy=x^Ty$. \n",
    "\n",
    "#### Problem I.5.5\n",
    "\n",
    "If $Q$ is orthogonal, then there are $n$ bases for matrix $Q$, and they are all independent of each other because of the orthogonality property. So the rank of $Q$ is $n$, which says it is invertible. \n",
    "Since $Q^{-1}=Q^T$, we have $QQ^{-1}=QQ^T=I$, which says the columns of $Q^T$ i.e., the rows of $Q$ are orthogonal, rows of $Q$ are actually columns of $Q^{-1}$, so we know $Q^{-1}$ is also orthogonal. \n",
    "\n",
    "If $Q^T_1=Q^{-1}_1$ and $Q^T_2=Q^{-1}_2$, we have $(Q_1Q_2)^T(Q_1Q_2)=Q_2^TQ_1^TQ_1Q_2=Q_2^TQ^{-1}_1Q_1Q_2=Q^{-1}_2Q_2=I$.\n",
    "\n",
    "So $Q_1Q_2$ is an orthogonal matrix. \n",
    "\n",
    "#### Problem I.5.6\n",
    "\n",
    "Suppose the columns of $P$ are $p_1,\\dots, p_n$, then we have $p^T_ip_j = 0$ if $i\\ne j$, and $1$ is $i=j$. So $P^TP$=I$ and $P$ is square so it's orthogonal.\n",
    "\n",
    "$P$ is orthogonal, so $P^TP=I$ and $P^{-1}=P^T$. \n",
    "\n",
    "When a matrix is symmetric or orthogonal, it will have orthogonal eigenvectors.\n",
    "\n",
    "#### Problem I.5.7\n",
    "\n",
    "* $\\bar{x}^T_1x_1 = 4$\n",
    "* $\\bar{x}^T_2x_2 = \\begin{bmatrix}1 & -i & -1 & i \\end{bmatrix}\\begin{bmatrix}1 \\\\ i \\\\ -1 \\\\ -i \\end{bmatrix} = 4$\n",
    "* $\\bar{x}^T_3x_3 = \\begin{bmatrix}1 & -1 & 1 & -1 \\end{bmatrix}\\begin{bmatrix}1 \\\\ -1 \\\\ 1 \\\\ -1 \\end{bmatrix} = 4$\n",
    "* $\\bar{x}^T_4x_4 = \\begin{bmatrix}1 & i & -1 & i \\end{bmatrix}\\begin{bmatrix}1 \\\\ -i \\\\ -1 \\\\ -i \\end{bmatrix} = 4$\n",
    "* $\\bar{x}^T_1x_2 = \\begin{bmatrix}1 & 1 & 1 & 1 \\end{bmatrix}\\begin{bmatrix}1 \\\\ i \\\\ -1 \\\\ -i \\end{bmatrix} = 0$\n",
    "\n",
    "It's easy to check that for $i\\ne j$, $\\bar{x}^T_ix_j = 0$, so $\\bar{Q}^TQ=I$.\n",
    "\n",
    "#### Problem I.5.8\n",
    "\n",
    "$W^TW=\\begin{bmatrix}4 & 0 & 0 & 0 \\\\ 0 & 4 & 0 & 0 \\\\ 0 & 0 & 2 & 0 \\\\ 0 & 0 & 0 & 2\\end{bmatrix}$\n",
    "\n",
    "$W^{-1} = \\begin{bmatrix}\\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} & \\frac{1}{4} \\\\ \\frac{1}{4} & \\frac{1}{4} & -\\frac{1}{4} & -\\frac{1}{4} \\\\ \\frac{1}{2} & -\\frac{1}{2} & 0 & 0 \\\\ 0 & 0 & \\frac{1}{2} & -\\frac{1}{2}\\end{bmatrix}$\n",
    "\n",
    "The $n=8$ Harr wavelets are: (TODO)\n",
    "\n",
    "$W_8=\\begin{bmatrix}W_4 & 0 \\\\ 0 & W_4\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem I.6.1\n",
    "\n",
    "$\\lambda_1 + \\lambda_2 = trace(Q) = 2\\cos\\theta$\n",
    "\n",
    "The determinant $|Q|=\\cos^2\\theta+\\sin^2\\theta=1$, whereas $\\lambda_1\\lambda_2 = (\\cos\\theta + i\\sin\\theta)(\\cos\\theta - i\\sin\\theta)=\\cos^2\\theta + \\sin^2\\theta = 1$. \n",
    "\n",
    "$\\bar{x}_1\\cdot x_2 = (1+i)\\cdot (1+i) = 1 + i^2 = 0$\n",
    "\n",
    "$Q^{-1} = \\begin{bmatrix}\\cos\\theta & \\sin\\theta \\\\-\\sin\\theta & \\cos\\theta\\end{bmatrix}$\n",
    "\n",
    "Its eigenvalues are $\\frac{1}{\\lambda_1}$ and $\\frac{1}{\\lambda_2}$\n",
    "\n",
    "#### Problem I.6.2\n",
    "\n",
    "The eigenvalues of $A$ are: $\\lambda_1 = 2$, $\\lambda_2 = -1$. The eigenvectors are $v_1 = \\begin{bmatrix}1 \\\\1 \\end{bmatrix}$, and $v_2 = \\begin{bmatrix}-2 \\\\ 1\\end{bmatrix}$.\n",
    "\n",
    "The eigenvalues of $A^{-1}$ are: $\\lambda_1 = \\frac{1}{2}$, $\\lambda_2 = -1$. The eigenvectors are $v_1 = \\begin{bmatrix}1 \\\\1 \\end{bmatrix}$, and $v_2 = \\begin{bmatrix}-2 \\\\ 1\\end{bmatrix}$\n",
    "\n",
    "$A^{-1}$ has the same eigenvectors as $A$. When $A$ has eigenvalues $\\lambda_1$ and $\\lambda_2$, its inverse has eigenvalues $\\lambda^{-1}_1$, and $\\lambda^{-1}_2$. \n",
    "\n",
    "#### Problem I.6.3\n",
    "\n",
    "Eigenvalues of $A$ are:  $\\lambda_1 = 3$, $\\lambda_2 = 1$.\n",
    "Eigenvalues of $B$ are:  $\\lambda_1 = 1$, $\\lambda_2 = 3$.\n",
    "Eigenvalues of $A+B$ are:  $\\lambda_1 = 5$, $\\lambda_2 = 3$.\n",
    "\n",
    "So eigenvalues $A+B$ are not equal to eigenvalues of $A$ plus eigenvalues of $B$.\n",
    "\n",
    "#### Problem I.6.4\n",
    "\n",
    "* Eigenvalues of $A$ are:  $\\lambda_1 = 1$, $\\lambda_2 = 1$.\n",
    "* Eigenvalues of $B$ are:  $\\lambda_1 = 1$, $\\lambda_2 = 1$.\n",
    "* Eigenvalues of $AB$ are:  $\\lambda_1 = 2+\\sqrt{3}$, $\\lambda_2 = 2-\\sqrt{3}$.\n",
    "* Eigenvalues of $BA$ are:  $\\lambda_1 = 2+\\sqrt{3}$, $\\lambda_2 = 2-\\sqrt{3}$.\n",
    "\n",
    "* (a) The eigenvalues of $AB$ are not equal to eigenvalues of $A$ times eigenvalues of $B$.\n",
    "* (b) The eigenvalues of $AB$ equal to the eigenvalues of $BA$.\n",
    "\n",
    "#### Problem I.6.5\n",
    "\n",
    "* (a) If you know that $x$ is an eigenvector, the way to find $\\lambda$ is to use $Ax=\\lambda x$ and solve for $\\lambda$.\n",
    "* (b) If you know that $\\lambda$ is an eigenvalue, the way to find $x$ is to solve $Ax=\\lambda x$.\n",
    "\n",
    "#### Problem I.6.6\n",
    "\n",
    "* The eigenvalues of $A$ are: $\\lambda_1 = 0.4$, $\\lambda_2 = 1$. The eigenvectors are $v_1=\\begin{bmatrix}1 \\\\ -1\\end{bmatrix}$ and $v_2=\\begin{bmatrix}1 \\\\ 2\\end{bmatrix}$\n",
    "* The eigenvalues of $A^{\\infty}$ are: $\\lambda_1 = 0$, $\\lambda_2 = 1$. The eigenvectors are $v_1=\\begin{bmatrix}1 \\\\ -1\\end{bmatrix}$ and $v_2=\\begin{bmatrix}1 \\\\ 2\\end{bmatrix}$\n",
    "\n",
    "The eigenvalues of $A^{100}$ are  $\\lambda_1 = 0.4^{100} = 1.6e-40$, $\\lambda_2 = 1^{100}=1$.\n",
    "\n",
    "Since $A=X\\Lambda X^{-1}$, $A^{100}=X\\Lambda^{100}X^{-1}$, the $\\Lambda^{100}$ approach the eigenvalues $\\Lambda_{\\infty}$ of $A^{\\infty}$, and $A$ and $A^{\\infty}$ both have the same eigenvectors, $A^{\\infty}=X\\Lambda_{\\infty}X^{-1}$, so $A^{100}$  is close to $A^{\\infty}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem I.6.7\n",
    "\n",
    "$det A = \\lambda_1\\lambda_2\\dots\\lambda_n$\n",
    "\n",
    "#### Problem I.6.8\n",
    "\n",
    "The quadratic formula gives the eigenvalues $\\lambda_1=\\frac{a+d + \\sqrt{(a+d)^2-4(ad-bc)}}{2}$ and $\\lambda_2=\\frac{a+d - \\sqrt{(a+d)^2-4(ad-bc)}}{2}$. Their sum is $a+d$. \n",
    "\n",
    "If $A$ has $\\lambda_1=3$ and $\\lambda_2=4$, then $det(A-\\lambda I)=(\\lambda - 3)(\\lambda - 4)$\n",
    "\n",
    "#### Problem I.6.9\n",
    "\n",
    "We select different combinations of $a$ and $d$ to have $a+d=9$, then make the determinant of $A$ equal to 20. \n",
    "\n",
    "* $A_1=\\begin{bmatrix}4 & 1 \\\\ 0 & 5\\end{bmatrix}$\n",
    "* $A_2=\\begin{bmatrix}5 & 0 \\\\ 1 & 4\\end{bmatrix}$\n",
    "* $A_3=\\begin{bmatrix}3 & -1 \\\\ 2 & 6\\end{bmatrix}$\n",
    "\n",
    "#### Problem I.6.10\n",
    "\n",
    "Apply $det(A-\\lambda I) = (\\lambda - \\lambda_1)\\dots(\\lambda - \\lambda_n)$\n",
    "\n",
    "* $A=\\begin{bmatrix}0 & 1 \\\\ -28 & 11\\end{bmatrix}$\n",
    "* $C=\\begin{bmatrix}0 & 1 & 0\\\\ 0 & 0& 1\\\\ 6 &-11 &6\\end{bmatrix}$\n",
    "\n",
    "#### Problem I.6.11\n",
    "\n",
    "The eigenvalues of $A$ equal the eigenvalues of $A^T$. This is because the determinant of a matrix $A$ equals to the determinant of its transpose $A^T$, so $det(A-\\lambda I ) = det(A-\\lambda I)^T = det(A^T - \\lambda I)$.\n",
    "\n",
    "Example, for $A=\\begin{bmatrix}0 & 2\\\\1 &1\\end{bmatrix}$\n",
    "\n",
    "The eigenvalues of $A$ are: $\\lambda_1 = 2$, $\\lambda_2 = -1$. The eigenvectors are $v_1 = \\begin{bmatrix}1 \\\\1 \\end{bmatrix}$, and $v_2 = \\begin{bmatrix}-2 \\\\ 1\\end{bmatrix}$.\n",
    "\n",
    "The eigenvalues of $A^T$ are: $\\lambda_1 = 2$, $\\lambda_2 = -1$. The eigenvectors are $v_1 = \\begin{bmatrix}1 \\\\2 \\end{bmatrix}$, and $v_2 = \\begin{bmatrix}1 \\\\ -1\\end{bmatrix}$.\n",
    "\n",
    "#### Problem I.6.12\n",
    "\n",
    "There are algebraic multiplicity of 2, where $\\lambda_{1,2}=0$ and $\\lambda_3=6$. \n",
    "\n",
    "We have eigenvectors from $Ax=\\lambda x$:\n",
    "* When $\\lambda=6$, the eigenvector is $v_1 = \\begin{bmatrix}1 \\\\ 2 \\\\1 \\end{bmatrix}$\n",
    "* When $\\lambda =0$, we have $Ax=0$, so the eigenvectors are in the nullspace of $A$, e.g. $v_2 = \\begin{bmatrix}1 \\\\ -1 \\\\-1 \\end{bmatrix}$ and $v_3 = \\begin{bmatrix}1 \\\\ 1 \\\\-3 \\end{bmatrix}$\n",
    "\n",
    "There are two independent eigenvectors for $\\lambda = 0$, so the geometric multiplicity = 2 as well.\n",
    "\n",
    "#### Problem I.6.13\n",
    "\n",
    "Any vector $x$ is a combination $x = c_1x_1+\\dots + c_nx_n$, then \n",
    "\n",
    "* $Ax = A(c_1x_1+\\dots + c_nx_n) = c_1Ax_1 + \\dots + c_nAx_n = c_1\\lambda_1x_1 + \\dots + c_n \\lambda_n x_n$\n",
    "\n",
    "* $Bx = B(c_1x_1+\\dots + c_nx_n) = c_1Bx_1 + \\dots + c_nBx_n = c_1\\lambda_1x_1 + \\dots + c_n \\lambda_n x_n$\n",
    "\n",
    "So we have $Ax=Bx$ for any $x$, take $x=1$, we have $A=B$.\n",
    "\n",
    "#### Problem I.6.14\n",
    "\n",
    "* (a) Since $Au=0$, so $u$ is a basis for the nullspace. Since $Av=3v$ and $Aw=5w$, also $v$ and $w$ are independent, so both $v$ and $w$ are bases for the column space. \n",
    "\n",
    "* (b) We have $x=\\frac{1}{3}v + \\frac{1}{5}w$, so $Ax = A(\\frac{1}{3}v + \\frac{1}{5}w)=\\frac{1}{3}Av+\\frac{1}{5}Aw=\\frac{1}{3}3v+\\frac{1}{5}5w = v + w$\n",
    "\n",
    "* (c) $Ax=u$ has no solution. If it did then $u$ would be in the column space, which contradicts with $Au=0$, meaning $u$ is in the nullspace.\n",
    "\n",
    "#### Problem I.6.15\n",
    "\n",
    "* (a) $A=\\begin{bmatrix}1 & 2 \\\\0 & 3\\end{bmatrix}$, it has eigenvalues $\\lambda_1 = 1$, and $\\lambda_2 = 3$. \n",
    "It has eigenvectors $v_1=\\begin{bmatrix}1 \\\\0\\end{bmatrix}$, $v_2=\\begin{bmatrix}1 \\\\1\\end{bmatrix}$. \n",
    "So we have $A=\\begin{bmatrix}1 & 1 \\\\0 & 1\\end{bmatrix}\\begin{bmatrix}1 & 0 \\\\0 & 3\\end{bmatrix}\\begin{bmatrix}1 & -1 \\\\0 & 1\\end{bmatrix}$\n",
    "\n",
    "$A=\\begin{bmatrix}1 & 1 \\\\3 & 3\\end{bmatrix}$, it has eigenvalues $\\lambda_1 = 0$, and $\\lambda_2 = 4$. \n",
    "It has eigenvectors $v_1=\\begin{bmatrix}1 \\\\-1\\end{bmatrix}$, $v_2=\\begin{bmatrix}1 \\\\3\\end{bmatrix}$. \n",
    "So we have $A=\\begin{bmatrix}1 & 1 \\\\-1 & 3\\end{bmatrix}\\begin{bmatrix}0 & 0 \\\\0 & 4\\end{bmatrix}\\begin{bmatrix}\\frac{3}{4} & -\\frac{1}{4} \\\\\\frac{1}{4} & \\frac{1}{4}\\end{bmatrix}$\n",
    "\n",
    "* (b) If $A=X\\Lambda X^{-1}$, then $A^3=X\\Lambda^3 X^{-1}$ and $A^{-1}=X\\Lambda^{-1}X^{-1}$\n",
    "\n",
    "#### Problem I.6.16\n",
    "\n",
    "If $A=X\\Lambda X^{-1}$, then $A+2I=X\\Lambda X^{-1} + 2XX^{-1} = X(\\Lambda + 2)X^{-1}$, the eigenvalue matrix is $\\Lambda + 2$. The eigenvector matrix is the same as $A$. \n",
    "\n",
    "#### Problem I.6.17\n",
    "\n",
    "If the columns of $X$, eigenvectors of $A$, are linearly independent, then \n",
    "\n",
    "* (a) $A$ is invertible: False, we need the columns of $A$ are independent\n",
    "* (b) $A$ is diagonalizable: False, we may have Geometric multiplicity < Algebraic multiplicity, so $A$ is not diagonalizable.\n",
    "* (c) $X$ is invertible: True\n",
    "* (d) $X$ is diagonalizable: True. for any $x$, we have $Xx=x$, the eigenvalues of $X$ are 1, and the diagonal matrix is $I$ for $X$.\n",
    "\n",
    "#### Problem I.6.18\n",
    "\n",
    "Assume $A=\\begin{bmatrix}a & b \\\\ c & d \\end{bmatrix}$, and take $Ax_1=\\lambda_1x_1$ and $Ax_2=\\lambda_2x_2$ for the two eigenvectors, solve for the $a,b,c,d$, we see that $a=d$, $b=c$, so $A=\\begin{bmatrix}a & b \\\\ b & a \\end{bmatrix}$\n",
    "\n",
    "#### Problem I.6.19\n",
    "If the eigenvalues of $A$ are 2, 2, 5 then\n",
    "\n",
    "* (a) $A$ is invertible: False, only if $A$ has full rank.\n",
    "* (b) $A$ is diagonalizable: False, if $GM < AM$ it's not diagonalizable.\n",
    "* (c) $A$ is not diagonalizable: False, if $GM=AM$, it diagonalizable.\n",
    "\n",
    "#### Problem I.6.20\n",
    "\n",
    "If the only eigenvectors of $A$ are multiples of $(1,4)$, then A has\n",
    "\n",
    "* (a) no inverse: True. \n",
    "* (b) a repeated eigenvalue: False, the $GM=1$, so we have $AM\\ge GM=2$, if we have $AM=1$ as well, there no repeated eigenvalue.\n",
    "* (c) no diagonalization $X\\Lambda X^{-1}$: True, we don't have $X^{-1}$ available.\n",
    "\n",
    "#### Problem I.6.21\n",
    "\n",
    "$A^k = X\\Lambda^{k}X^{-1}$ approaches the zero matrix as $k\\to \\infty$ if and only if every $\\lambda$ has absolute value less than $1$. The matrix $A_1$ has eigenvalues of $\\lambda_1 = 1$ and $\\lambda_2 = -0.3$, while $A_2$ has eigenvalues of $\\lambda_1 = 0.3$ and $\\lambda_2 = 0.9$ both of which have absolute value less than 1. \n",
    "\n",
    "So $A_2$ will has $A^k_2 \\to 0$. While $A_1$ has an eigenvalue of $1$, it won't go to zero.\n",
    "\n",
    "\n",
    "#### Problem I.6.22\n",
    "$A$ has eigenvalues of $\\lambda_1 = 1$ and $\\lambda_2=3$, with corresponding eigenvectors $v_1=\\begin{bmatrix}1 \\\\1 \\end{bmatrix}$ and $v_2=\\begin{bmatrix}1 \\\\-1 \\end{bmatrix}$. So we have\n",
    "\n",
    "$A=X\\Lambda X^{-1} = \\begin{bmatrix}1 &1 \\\\1 & -1 \\end{bmatrix}\\begin{bmatrix}1 &0 \\\\0 & 3 \\end{bmatrix}\\begin{bmatrix}\\frac{1}{2} &\\frac{1}{2} \\\\\\frac{1}{2} & -\\frac{1}{2} \\end{bmatrix}$\n",
    "\n",
    "$A^{k} = \\begin{bmatrix}1 &1 \\\\1 & -1 \\end{bmatrix}\\begin{bmatrix}1 &0 \\\\0 & 3^k \\end{bmatrix}\\begin{bmatrix}\\frac{1}{2} &\\frac{1}{2} \\\\\\frac{1}{2} & -\\frac{1}{2} \\end{bmatrix} = \\frac{1}{2}\\begin{bmatrix}1+3^k &1-3^k \\\\1-3^k & 1+3^k \\end{bmatrix}$\n",
    "\n",
    "#### Problem I.6.23\n",
    "\n",
    "The $X=\\begin{bmatrix}1 & 1 \\\\-1 & 1 \\end{bmatrix}$, so $X^{-1} = \\begin{bmatrix}\\frac{1}{2} & -\\frac{1}{2} \\\\\\frac{1}{2} & \\frac{1}{2} \\end{bmatrix}$. And $\\Lambda = \\begin{bmatrix}1 & 0 \\\\0 & 9 \\end{bmatrix}$.\n",
    "\n",
    "We have $A=X\\Lambda X^{-1}$ and square root of $A$ is: $R=X\\sqrt{\\Lambda} X^{-1}=\\begin{bmatrix}1 & 1 \\\\-1 & 1 \\end{bmatrix}\\begin{bmatrix}1 & 0 \\\\0 & 3 \\end{bmatrix}\\begin{bmatrix}\\frac{1}{2} & -\\frac{1}{2} \\\\\\frac{1}{2} & \\frac{1}{2} \\end{bmatrix} = \\begin{bmatrix}2 & 1 \\\\1 & 2 \\end{bmatrix}$.\n",
    "\n",
    "Ther is no real matrix square root of $B$ because the first eigenvalue is $-1 < 0$, so no real square root here.\n",
    "\n",
    "#### Problem I.6.24\n",
    "\n",
    "* $AB=X\\Lambda_1 X^{-1} X \\Lambda_2 X^{-1} = X \\Lambda_1\\Lambda_2X^{-1}$\n",
    "* $BA=X\\Lambda_2 X^{-1} X \\Lambda_1 X^{-1} = X \\Lambda_1\\Lambda_2X^{-1}$\n",
    "\n",
    "So $AB=BA$.\n",
    "\n",
    "#### Problem I.6.25 TODO\n",
    "\n",
    "#### Problem I.6.26\n",
    "\n",
    "$A$ and $\\Lambda$ always have the same eigenvalues. But similarity requires a matrix $B$ with $A=B\\Lambda B^{-1}$. Then $B$ is the eigenvector matrix and $A$ must have $n$ independent eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
